SET search_path TO documentdb_api_catalog, documentdb_core, public;
SET documentdb.next_collection_id TO 400;
SET documentdb.next_collection_index_id TO 400;
CREATE OR REPLACE FUNCTION documentdb_api_internal.rum_prune_empty_entries_on_index(index_relid regclass)
RETURNS void
LANGUAGE c
AS '$libdir/pg_documentdb_extended_rum_core', 'documentdb_rum_prune_empty_entries_on_index';
ALTER SYSTEM set autovacuum to off;
SELECT pg_reload_conf();
 pg_reload_conf 
----------------
 t
(1 row)

SELECT name, setting, reset_val, boot_val FROM pg_settings WHERE name in ('documentdb_rum.track_incomplete_split', 'documentdb_rum.fix_incomplete_split');
                 name                  | setting | reset_val | boot_val 
---------------------------------------+---------+-----------+----------
 documentdb_rum.fix_incomplete_split   | on      | on        | on
 documentdb_rum.track_incomplete_split | on      | on        | on
(2 rows)

SELECT documentdb_api.drop_collection('pvacuum_db', 'pclean');
 drop_collection 
-----------------
 f
(1 row)

SELECT COUNT(documentdb_api.insert_one('pvacuum_db', 'pclean',  FORMAT('{ "_id": %s, "a": %s }', i, i)::bson)) FROM generate_series(1, 1000) AS i;
NOTICE:  creating collection
 count 
-------
  1000
(1 row)

SELECT documentdb_api_internal.create_indexes_non_concurrently(
    'pvacuum_db',
    '{ "createIndexes": "pclean", "indexes": [ { "key": { "a": 1 }, "name": "a_1", "enableCompositeTerm": true } ] }', TRUE);
                                                                                                   create_indexes_non_concurrently                                                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 { "raw" : { "defaultShard" : { "numIndexesBefore" : { "$numberInt" : "1" }, "numIndexesAfter" : { "$numberInt" : "2" }, "createdCollectionAutomatically" : false, "ok" : { "$numberInt" : "1" } } }, "ok" : { "$numberInt" : "1" } }
(1 row)

-- use the index - 
set documentdb_rum.vacuum_cleanup_entries to off;
set documentdb.enableExtendedExplainPlans to on;
set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                run_explain_and_trim                                 
-------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=1000 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 1000 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 1000)]
         ->  Bitmap Heap Scan on documents_401 collection (actual rows=1000 loops=1)
               Recheck Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Blocks: exact=10
               ->  Bitmap Index Scan on a_1 (actual rows=1000 loops=1)
                     Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
(13 rows)

-- drop all the rows now
reset documentdb.forceDisableSeqScan;
DELETE FROM documentdb_data.documents_401 WHERE object_id >= '{ "": 10 }';
set documentdb.forceDisableSeqScan to on;
-- query again (should return 10 rows with 1000 loops)
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                run_explain_and_trim                                
------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=9 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 1000 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 1000)]
         ->  Bitmap Heap Scan on documents_401 collection (actual rows=9 loops=1)
               Recheck Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Blocks: exact=10
               ->  Bitmap Index Scan on a_1 (actual rows=1000 loops=1)
                     Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
(13 rows)

-- vacuum the collection
VACUUM (FREEZE ON, INDEX_CLEANUP ON, DISABLE_PAGE_SKIPPING ON) documentdb_data.documents_401;
-- query again (should return 10 rows but still with 1000 loops since we don't clean entries).
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                   run_explain_and_trim                                    
-------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=9 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 1000 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 9)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=9 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

reset documentdb.forceDisableSeqScan;
SELECT COUNT(documentdb_api.insert_one('pvacuum_db', 'pclean',  FORMAT('{ "_id": %s, "a": %s }', i, i)::bson)) FROM generate_series(1001, 2000) AS i;
 count 
-------
  1000
(1 row)

DELETE FROM documentdb_data.documents_401 WHERE object_id >= '{ "": 1010 }';
set documentdb.forceDisableSeqScan to on;
-- now set the guc to clean the entries
set documentdb_rum.vacuum_cleanup_entries to on;
VACUUM (FREEZE ON, INDEX_CLEANUP ON, DISABLE_PAGE_SKIPPING ON) documentdb_data.documents_401;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                    run_explain_and_trim                                    
--------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=18 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 31 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 18)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=18 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

-- repeat one more time
reset documentdb.forceDisableSeqScan;
SELECT COUNT(documentdb_api.insert_one('pvacuum_db', 'pclean',  FORMAT('{ "_id": %s, "a": %s }', i, i)::bson)) FROM generate_series(2001, 3000) AS i;
 count 
-------
  1000
(1 row)

DELETE FROM documentdb_data.documents_401 WHERE object_id >= '{ "": 2010 }';
set documentdb.forceDisableSeqScan to on;
-- now set the guc to clean the entries
set documentdb_rum.vacuum_cleanup_entries to on;
VACUUM (FREEZE ON, INDEX_CLEANUP ON, DISABLE_PAGE_SKIPPING ON) documentdb_data.documents_401;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                    run_explain_and_trim                                    
--------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=27 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 45 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 27)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=27 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

reset documentdb.forceDisableSeqScan;
-- insert some entries to create posting trees.
SELECT COUNT(documentdb_api.insert_one('pvacuum_db', 'pclean',  FORMAT('{ "_id": -%s, "a": 500 }', i)::bson)) FROM generate_series(1, 3000) AS i;
 count 
-------
  3000
(1 row)

-- now delete everything includig posting tree entries.
DELETE FROM documentdb_data.documents_401 WHERE object_id < '{ "": 2000 }';
set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                run_explain_and_trim                                
------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=9 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 46 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 3027)]
         ->  Bitmap Heap Scan on documents_401 collection (actual rows=9 loops=1)
               Recheck Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Blocks: exact=29
               ->  Bitmap Index Scan on a_1 (actual rows=3027 loops=1)
                     Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
(13 rows)

-- now set the guc to clean up entry pages
set documentdb_rum.prune_rum_empty_pages to on;
set client_min_messages to DEBUG1;
VACUUM (FREEZE ON, INDEX_CLEANUP ON, DISABLE_PAGE_SKIPPING ON) documentdb_data.documents_401;
DEBUG:  [RUM] Vacuum posting tree void pages 0, deleted pages 0
LOG:  Vacuum found 17 empty pages, 36 empty entries, 1 empty posting trees, 18 pruned entries, 15 pruned pages, 1 pruned empty posting trees for index 19102
LOG:  Vacuum pages - marked 1 pages as reusable
reset client_min_messages;
-- delete one more row to ensure vacuum has a chance to clean up
reset documentdb.forceDisableSeqScan;
DELETE FROM documentdb_data.documents_401 WHERE object_id <= '{ "": 2000 }';
set client_min_messages to DEBUG1;
VACUUM (FREEZE ON, INDEX_CLEANUP ON, DISABLE_PAGE_SKIPPING ON) documentdb_data.documents_401;
LOG:  Vacuum pages - marked 16 pages as reusable
reset client_min_messages;
set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                   run_explain_and_trim                                    
-------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=9 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 12 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 9)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=9 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

-- introduce dead pages and use the repair functions to clean up the index.
reset documentdb.forceDisableSeqScan;
CALL documentdb_api.drop_indexes('pvacuum_db', '{ "dropIndexes": "pclean", "index": "a_1" }');
                          retval                          
----------------------------------------------------------
 { "ok" : true, "nIndexesWas" : { "$numberLong" : "2" } }
(1 row)

TRUNCATE documentdb_data.documents_401;
-- now repeat without the vacuum
SELECT documentdb_api_internal.create_indexes_non_concurrently(
    'pvacuum_db',
    '{ "createIndexes": "pclean", "indexes": [ { "key": { "a": 1 }, "name": "a_1", "enableCompositeTerm": true } ] }', TRUE);
                                                                                                   create_indexes_non_concurrently                                                                                                    
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 { "raw" : { "defaultShard" : { "numIndexesBefore" : { "$numberInt" : "1" }, "numIndexesAfter" : { "$numberInt" : "2" }, "createdCollectionAutomatically" : false, "ok" : { "$numberInt" : "1" } } }, "ok" : { "$numberInt" : "1" } }
(1 row)

\d documentdb_data.documents_401
           Table "documentdb_data.documents_401"
     Column      |  Type  | Collation | Nullable | Default 
-----------------+--------+-----------+----------+---------
 shard_key_value | bigint |           | not null | 
 object_id       | bson   |           | not null | 
 document        | bson   |           | not null | 
Indexes:
    "collection_pk_401" PRIMARY KEY, btree (shard_key_value, object_id)
    "documents_rum_index_403" documentdb_extended_rum (document documentdb_extended_rum_catalog.bson_extended_rum_composite_path_ops (pathspec='[ "a" ]', tl='2691'))
Check constraints:
    "shard_key_value_check" CHECK (shard_key_value = '401'::bigint)

-- insert 3000 docs
SELECT COUNT(documentdb_api.insert_one('pvacuum_db', 'pclean',  FORMAT('{ "_id": %s, "a": %s }', i, i)::bson)) FROM generate_series(1, 3000) AS i;
 count 
-------
  3000
(1 row)

set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                run_explain_and_trim                                 
-------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=3000 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 3000 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 3000)]
         ->  Bitmap Heap Scan on documents_401 collection (actual rows=3000 loops=1)
               Recheck Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Blocks: exact=29
               ->  Bitmap Index Scan on a_1 (actual rows=3000 loops=1)
                     Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
(13 rows)

reset documentdb.forceDisableSeqScan;
-- delete 3000 docs
set documentdb_rum.vacuum_cleanup_entries to off;
set documentdb_rum.prune_rum_empty_pages to off;
DELETE FROM documentdb_data.documents_401;
VACUUM (FREEZE ON, INDEX_CLEANUP ON, DISABLE_PAGE_SKIPPING ON) documentdb_data.documents_401;
-- we should have a lot of empty pages
set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                   run_explain_and_trim                                    
-------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=0 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 3000 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 0)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=0 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

reset documentdb.forceDisableSeqScan;
-- call the repair function.
set documentdb_rum.vacuum_cleanup_entries to on;
SELECT documentdb_api_internal.rum_prune_empty_entries_on_index('documentdb_data.documents_rum_index_403'::regclass);
INFO:  Vacuum found 20 empty pages, 3000 empty entries, 2980 pruned entries, 0 pruned pages, 0 pruned posting trees
 rum_prune_empty_entries_on_index 
----------------------------------
 
(1 row)

-- should have fewer entries due to pruning.
set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                   run_explain_and_trim                                    
-------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=0 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 20 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 0)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=0 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

reset documentdb.forceDisableSeqScan;
set documentdb_rum.prune_rum_empty_pages to on;
SELECT documentdb_api_internal.rum_prune_empty_entries_on_index('documentdb_data.documents_rum_index_403'::regclass);
INFO:  Vacuum found 20 empty pages, 20 empty entries, 0 pruned entries, 18 pruned pages, 0 pruned posting trees
 rum_prune_empty_entries_on_index 
----------------------------------
 
(1 row)

set documentdb.forceDisableSeqScan to on;
SELECT documentdb_test_helpers.run_explain_and_trim($cmd$ EXPLAIN (COSTS OFF, ANALYZE ON, VERBOSE OFF, BUFFERS OFF, SUMMARY OFF, TIMING OFF) SELECT document FROM bson_aggregation_count('pvacuum_db', '{ "count": "pclean", "query": { "a": { "$exists": true } } }') $cmd$);
                                   run_explain_and_trim                                    
-------------------------------------------------------------------------------------------
 Aggregate (actual rows=1 loops=1)
   ->  Custom Scan (DocumentDBApiExplainQueryScan) (actual rows=0 loops=1)
         indexName: a_1
         isMultiKey: false
         indexBounds: ["a": [MinKey, MaxKey]]
         innerScanLoops: 2 loops
         scanType: ordered
         scanKeyDetails: key 1: [(isInequality: true, estimatedEntryCount: 0)]
         ->  Index Only Scan using a_1 on documents_401 collection (actual rows=0 loops=1)
               Index Cond: (document @>= '{ "a" : { "$minKey" : 1 } }'::bson)
               Heap Fetches: 0
(11 rows)

reset documentdb.forceDisableSeqScan;
ALTER SYSTEM set autovacuum to on;
SELECT pg_reload_conf();
 pg_reload_conf 
----------------
 t
(1 row)

